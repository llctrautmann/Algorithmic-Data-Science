{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Data Science: Lab 7 - Similarity\n",
    " \n",
    "Below, we create a list of docs - which are the course descriptions for the core modules on the Sussex MSc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "\n",
    "docs.append(\"The module teaches the computer science aspects of data science. A particular focus is on how data are represented and manipulated to achieve good performance on large data sets (> 10 GBytes) where standard techniques may no longer apply. In lectures, students will learn about data structures, algorithms, and systems, including distributed computing, databases (relational and non-relational), parallel computing, and cloud computing. In laboratory sessions, students will develop their Python programming skills; work with a variety of data sets including large data sets from real world applications; and investigate the impact on run-time of their algorithmic choices.\")\n",
    "\n",
    "docs.append(\"This module introduces you to the mathematical and statistical techniques used to analyse data. The module is fairly rigorous, and is aimed at students who have, or anticipate having, research data to analyse in a thorough and unbiased way.  Topics include: probability distributions; error propagation; maximum likelihood method and linear least squares fitting; chi-squared testing; subjective probability and Bayes' theorem; monte Carlo techniques; and non-linear least squares fitting.\")\n",
    "\n",
    "docs.append(\"In this module, you use literature to study the background to a problem in Data Science in your respective stream.  You choose your individual supervisor and devise a strategy by which this problem can be studied - giving details of techniques and resources that you will use to address the problem.  This research proposal forms the basis of the Data Science Dissertation that you will write in summer term.\")\n",
    "\n",
    "docs.append(\"For this module, you carry out independent study and research under the guide of a supervisor on a designated topic. You then complete a report on the subject over the summer.\")\n",
    "\n",
    "docs.append(\"In this module, you explore advanced techniques in machine learning. You use a systematic treatment, based on the following three key ingredients: tasks, models, features.  As part of the module, you are introduced to both regression and classification, and your studies emphasise concepts such as model performance, learnability and computational complexity.  You learn techniques including: probabilistic and non-probabilistic classification and regression methods, reinforcement learning approaches including the non-linear variants using kernel methods.  You are also introduced to techniques for pre-processing the data (including PCA). You will then need to be able to implement, develop and deploy these techniques to real-world problems.  In order to take this module, you need to have already taken the 'Mathematics & Computational Methods for Complex Systems' module (817G5), or have taken an equivalent mathematical module or have equivalent prior experience.\")\n",
    "\n",
    "docs.append(\"Your studies in this module include a series of seminars covering several topics - including national laws on data and ethical implications.  In addition, there are seminars by Data-Science-oriented companies.  You are expected to write a final dissertation of 3000 words, on a topic of your choice falling within the scope of the module.\")\n",
    "\n",
    "docs.append(\"This module will provide students with the practical tools and techniques required to build, analyse and interpret 'big data' datasets. It will cover all aspects of the Data Science process including collection, munging or wrangling, cleaning, exploratory data analysis, visualization, statistical inference and model building and implications for applications in the real world. During the module, they will be taught how to scrape data from the Internet, develop and test hypotheses, use principal component analysis (PCA) to reduce dimensionality, prepare actionable plans and present their findings. In the laboratory, students will develop their Python programming skills and be introduced to a number of fundamental standard Python libraries/toolkits for Data Scientists including NumPy, SciPy, PANDAS and SCIKIT-Learn. In these sessions and their coursework, students will work with real-world datasets and apply the techniques covered in lectures to that data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/luca/.pyenv/versions/3.10.0/envs/Summer_School/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/luca/.pyenv/versions/3.10.0/envs/Summer_School/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/luca/.pyenv/versions/3.10.0/envs/Summer_School/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/luca/.pyenv/versions/3.10.0/envs/Summer_School/lib/python3.10/site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: joblib in /Users/luca/.pyenv/versions/3.10.0/envs/Summer_School/lib/python3.10/site-packages (from nltk) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the nltk library to tokenise these.  Tokenization turns them into lists of words (and deals with punctuation better than if we just split the documents according to whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'module', 'teaches', 'the', 'computer', 'science', 'aspects', 'of', 'data', 'science', '.', 'A', 'particular', 'focus', 'is', 'on', 'how', 'data', 'are', 'represented', 'and', 'manipulated', 'to', 'achieve', 'good', 'performance', 'on', 'large', 'data', 'sets', '(', '>', '10', 'GBytes', ')', 'where', 'standard', 'techniques', 'may', 'no', 'longer', 'apply', '.', 'In', 'lectures', ',', 'students', 'will', 'learn', 'about', 'data', 'structures', ',', 'algorithms', ',', 'and', 'systems', ',', 'including', 'distributed', 'computing', ',', 'databases', '(', 'relational', 'and', 'non-relational', ')', ',', 'parallel', 'computing', ',', 'and', 'cloud', 'computing', '.', 'In', 'laboratory', 'sessions', ',', 'students', 'will', 'develop', 'their', 'Python', 'programming', 'skills', ';', 'work', 'with', 'a', 'variety', 'of', 'data', 'sets', 'including', 'large', 'data', 'sets', 'from', 'real', 'world', 'applications', ';', 'and', 'investigate', 'the', 'impact', 'on', 'run-time', 'of', 'their', 'algorithmic', 'choices', '.']\n"
     ]
    }
   ],
   "source": [
    "bags=[]\n",
    "for doc in docs:\n",
    "    bags.append(word_tokenize(doc))\n",
    "    \n",
    "print(bags[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this has an error, you probably need to run the nltk downloader on your machine to get the necessary resources. If this happens, then run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 9] Bad file\n",
      "[nltk_data]     descriptor>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write a function to turn a list of tokens into a dictionary of counts.  Apply this function to each of the lists in bags to create a representation for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 1, 'module': 1, 'teaches': 1, 'the': 2, 'computer': 1, 'science': 2, 'aspects': 1, 'of': 3, 'data': 6, '.': 4, 'A': 1, 'particular': 1, 'focus': 1, 'is': 1, 'on': 3, 'how': 1, 'are': 1, 'represented': 1, 'and': 5, 'manipulated': 1, 'to': 1, 'achieve': 1, 'good': 1, 'performance': 1, 'large': 2, 'sets': 3, '(': 2, '>': 1, '10': 1, 'GBytes': 1, ')': 2, 'where': 1, 'standard': 1, 'techniques': 1, 'may': 1, 'no': 1, 'longer': 1, 'apply': 1, 'In': 2, 'lectures': 1, ',': 8, 'students': 2, 'will': 2, 'learn': 1, 'about': 1, 'structures': 1, 'algorithms': 1, 'systems': 1, 'including': 2, 'distributed': 1, 'computing': 3, 'databases': 1, 'relational': 1, 'non-relational': 1, 'parallel': 1, 'cloud': 1, 'laboratory': 1, 'sessions': 1, 'develop': 1, 'their': 2, 'Python': 1, 'programming': 1, 'skills': 1, ';': 2, 'work': 1, 'with': 1, 'a': 1, 'variety': 1, 'from': 1, 'real': 1, 'world': 1, 'applications': 1, 'investigate': 1, 'impact': 1, 'run-time': 1, 'algorithmic': 1, 'choices': 1}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def dict_counts(l: list):\n",
    "    memo = {}\n",
    "    for i in range(len(l)):\n",
    "        if l[i] in memo:\n",
    "            pass\n",
    "        else:\n",
    "            memo[l[i]] = l.count(l[i])\n",
    "        \n",
    "    return memo\n",
    "\n",
    "      \n",
    "list_dicts = []\n",
    "\n",
    "\n",
    "for bag in bags:\n",
    "    list_dicts.append(dict_counts(bag))\n",
    "\n",
    "\n",
    "print(list_dicts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Write a function to compute the Jaccard similarity between two of your bags (represented as dictionaries). (You can find this in the lecture notes.) If you test it on the first two documents you should get a similarity of 0.132 (to 3SF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_dicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     union \u001b[39m=\u001b[39m maketotal(dict_1) \u001b[39m+\u001b[39m maketotal(dict_2) \u001b[39m-\u001b[39m intersectiontot\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m intersectiontot\u001b[39m/\u001b[39munion\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Jaccards(list_dicts[\u001b[39m0\u001b[39m],list_dicts[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_dicts' is not defined"
     ]
    }
   ],
   "source": [
    "def maketotal(dict_1):\n",
    "    total = 0\n",
    "    for item in dict_1:\n",
    "        total += dict_1[item]\n",
    "    return total\n",
    "\n",
    "\n",
    "def Jaccards(dict_1, dict_2):\n",
    "    intersection = {} \n",
    "    for item in dict_1.keys():\n",
    "        if item in dict_2.keys():\n",
    "            intersection[item]=min(dict_1[item],dict_2[item])\n",
    "            \n",
    "    intersectiontot = maketotal(intersection)\n",
    "    union = maketotal(dict_1) + maketotal(dict_2) - intersectiontot\n",
    "    \n",
    "    return intersectiontot/union\n",
    "    \n",
    "Jaccards(list_dicts[0],list_dicts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Compute all pairs Jaccard similarities for the 7 documents.  Which pair of documents are most similar?  Which pair are least similar?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2672811059907834, 1, 7)\n",
      "(0.05434782608695652, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "max_sim = tuple([0,0,0])\n",
    "\n",
    "min_sim = tuple([1,0,0])\n",
    "\n",
    "for i in range(len(list_dicts)):\n",
    "    for j in range(len(list_dicts)):\n",
    "        if i != j:\n",
    "            if max_sim[0] < Jaccards(list_dicts[i],list_dicts[j]):\n",
    "                max_sim = Jaccards(list_dicts[i],list_dicts[j]), i+1, j+1\n",
    "                \n",
    "            elif min_sim[0] > Jaccards(list_dicts[i],list_dicts[j]):\n",
    "                min_sim = Jaccards(list_dicts[i],list_dicts[j]), i+1, j+1\n",
    "            # print(f' The Jaccards similarity between {i+1} and {j+1} is {Jaccards(list_dicts[i],list_dicts[j])}')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "print(max_sim)\n",
    "print(min_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will turn the dictionary representation of documents into a characteristic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(list_of_dicts):\n",
    "    #first of all make a list of all of the features that occur in any document - these will be the dimensions of the matrix\n",
    "    allfeatures={}    \n",
    "    for docdict in list_of_dicts:\n",
    "        for feat in docdict.keys():\n",
    "            allfeatures[feat]=1\n",
    "    \n",
    "    dimensions=list(allfeatures.keys())\n",
    "    #don't strictly need to sort it - but it is good practise to make sure it is reproducible\n",
    "    sorted(dimensions)\n",
    "    \n",
    "    matrix=[]\n",
    "    #each row in the matrix will be one of the dimensions\n",
    "    for dimension in dimensions:\n",
    "        row=[]\n",
    "        #look up the appropriate value for each document\n",
    "        for docdict in list_of_dicts:\n",
    "            row.append(docdict.get(dimension,0)) #this will append the document's value if present, 0 otherwise\n",
    "        matrix.append(row)\n",
    "        \n",
    "        \n",
    "    return matrix\n",
    "\n",
    "## it might be useful to be able to transpose a matrix so we can compare documents\n",
    "def transpose(matrix):\n",
    "    transposed=[]\n",
    "    for i in range(0,len(matrix[0])):\n",
    "        transposed.append([row[i] for row in matrix])\n",
    "        \n",
    "    return transposed\n",
    "\n",
    "#call make_matrix on whatever variable holds your list of dictionaries representation of your documents\n",
    "\n",
    "\n",
    "# print(amatrix)\n",
    "# print(transpose(amatrix))      \n",
    "#\n",
    "\n",
    "amatrix=make_matrix(list_dicts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Write a function to compute the cosine similarity of two documents. (You can find this in the lecture notes.)  Test it on the first 2 documents - you should get 0.471(to 3SF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveCosine (a , b):\n",
    "    num=0\n",
    "    d1=0\n",
    "    d2=0\n",
    "    for i in range(len(a)):\n",
    "        num += a [ i ] *b [ i ]\n",
    "        d1 += a [ i ] *a [ i ]\n",
    "        d2 += b [ i ] *b [ i ]\n",
    "    return num / ( d1*d2 ) **0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4711695288325914"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naiveCosine(transpose(amatrix)[0],transpose(amatrix)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Compute the all pairs cosine similarities for the 6 documents.  Which is the most similar pair of documents?  Which is the least similar pair of documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7172112418628069, 1, 7)\n",
      "(0.26499947000158997, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "ver = False\n",
    "max_sim = tuple([0,0,0])\n",
    "\n",
    "min_sim = tuple([1,0,0])\n",
    "\n",
    "for i in range(len(transpose(amatrix))):\n",
    "    for j in range(len(transpose(amatrix))):\n",
    "        if i != j:\n",
    "            \n",
    "            if max_sim[0] < naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]):\n",
    "                max_sim = naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]), i+1, j+1\n",
    "                \n",
    "            elif min_sim[0] > naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]):\n",
    "                min_sim = naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]), i+1, j+1\n",
    "            \n",
    "            elif ver == True:\n",
    "                print(f' The Jaccards similarity between document {i+1} and document {j+1} is {naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j])}')\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "print(max_sim)\n",
    "print(min_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "What is the computational complexity of the Jaccard algorithm from Exercise 2? Test this empirically. What is the constant? You may want to make some longer documents - you could do this by concatenating different numbers of bags that were created for the original documents and / or sampling from a very large bag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(somefunc,*args,repeats=100,**kwargs):\n",
    "    times=[]\n",
    "    for i in range(repeats):\n",
    "        starttime=time.time()\n",
    "        ans=somefunc(*args,**kwargs)\n",
    "        endtime=time.time()\n",
    "        timetaken=endtime-starttime\n",
    "        times.append(timetaken)\n",
    "    \n",
    "    mean=np.mean(times)\n",
    "    stdev=np.std(times)\n",
    "    error=stdev/(repeats**0.5)\n",
    " \n",
    "    return (ans,mean,error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "What is the computational complexity of the cosine algorithm from Exercise 4?  Test this empirically.  What is the constant?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unreprievably'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random_word import RandomWords\n",
    "r = RandomWords()\n",
    "\n",
    "# Return a single random word\n",
    "r.get_random_word()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wlist_1 = [] # dont run this\n",
    "\n",
    "for i in range(100):\n",
    "    wlist_1.append(r.get_random_word())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /Users/luca/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "sent = reuters.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(length=15):\n",
    "    list_dicts = []\n",
    "\n",
    "    for i in range(len(sent[:length])):\n",
    "        list_dicts.append(dict_counts(sent[i]))\n",
    "        \n",
    "    return list_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" If the tariffs remain in place for any length of time beyond a few months it will mean the complete erosion of exports ( of goods subject to tariffs ) to the U . S .,\" said Tom Murtha , a stock analyst at the Tokyo office of broker & lt ; James Capel and Co >.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sent[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccards_docs(list_dicts: list):\n",
    "    max_sim = tuple([0,0,0])\n",
    "    min_sim = tuple([1,0,0])\n",
    "\n",
    "    for i in range(len(list_dicts)):\n",
    "        for j in range(len(list_dicts)):\n",
    "            if i != j:\n",
    "                if max_sim[0] < Jaccards(list_dicts[i],list_dicts[j]):\n",
    "                    max_sim = Jaccards(list_dicts[i],list_dicts[j]), i+1, j+1\n",
    "                    \n",
    "                elif min_sim[0] > Jaccards(list_dicts[i],list_dicts[j]):\n",
    "                    min_sim = Jaccards(list_dicts[i],list_dicts[j]), i+1, j+1\n",
    "                # print(f' The Jaccards similarity between {i+1} and {j+1} is {Jaccards(list_dicts[i],list_dicts[j])}')\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return max_sim, min_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.2672811059907834, 1, 7), (0.05434782608695652, 4, 7))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jaccards_docs(list_dicts=list_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dict = corpus(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "\n",
    "l = [10,15,25,35,45,55,65,75,85,95,105]\n",
    "\n",
    "for i in l:\n",
    "    xs.append(i)\n",
    "    list_dict = corpus(i)\n",
    "    \n",
    "    ans, mean, sd = timeit(Jaccards_docs, list_dict)\n",
    "    \n",
    "    ys.append(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x148ef89d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cosine_Similarity(amatrix: list):\n",
    "    max_sim = tuple([0,0,0])\n",
    "\n",
    "    min_sim = tuple([1,0,0])\n",
    "\n",
    "    for i in range(len(transpose(amatrix))):\n",
    "        for j in range(len(transpose(amatrix))):\n",
    "            if i != j:\n",
    "                \n",
    "                if max_sim[0] < naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]):\n",
    "                    max_sim = naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]), i+1, j+1\n",
    "                    \n",
    "                elif min_sim[0] > naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]):\n",
    "                    min_sim = naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]), i+1, j+1\n",
    "                \n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 done\n",
      "step 2 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m amatrix\u001b[39m=\u001b[39mmake_matrix(list_dict)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep 2 done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m ans, mean, sd \u001b[39m=\u001b[39m timeit(Cosine_Similarity, transpose(amatrix))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep 3 done\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ys\u001b[39m.\u001b[39mappend(mean)\n",
      "\u001b[1;32m/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb Cell 36\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(somefunc, repeats, *args, **kwargs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(repeats):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     starttime\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     ans\u001b[39m=\u001b[39msomefunc(\u001b[39m*\u001b[39;49margs,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     endtime\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     timetaken\u001b[39m=\u001b[39mendtime\u001b[39m-\u001b[39mstarttime\n",
      "\u001b[1;32m/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb Cell 36\u001b[0m in \u001b[0;36mCosine_Similarity\u001b[0;34m(amatrix)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(transpose(amatrix))):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mif\u001b[39;00m max_sim[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             max_sim \u001b[39m=\u001b[39m naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]), i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39melif\u001b[39;00m min_sim[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m naiveCosine(transpose(amatrix)[i],transpose(amatrix)[j]):\n",
      "\u001b[1;32m/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb Cell 36\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(matrix)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m transposed\u001b[39m=\u001b[39m[]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(matrix[\u001b[39m0\u001b[39m])):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     transposed\u001b[39m.\u001b[39mappend([row[i] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m matrix])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m transposed\n",
      "\u001b[1;32m/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb Cell 36\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m transposed\u001b[39m=\u001b[39m[]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(matrix[\u001b[39m0\u001b[39m])):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     transposed\u001b[39m.\u001b[39mappend([row[i] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m matrix])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/SU/Artificial_Intelligence/ADS/Scripts/unit4lab.ipynb#X51sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m transposed\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "\n",
    "l = [10,15,25]\n",
    "\n",
    "for i in l:\n",
    "    xs.append(i)\n",
    "    list_dict = corpus(i)\n",
    "    print('step 1 done')\n",
    "    \n",
    "    amatrix=make_matrix(list_dict)\n",
    "    print('step 2 done')\n",
    "    \n",
    "    ans, mean, sd = timeit(Cosine_Similarity, transpose(amatrix))\n",
    "    print('step 3 done')\n",
    "\n",
    "    ys.append(mean)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1\n",
      "3\n",
      "0\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print((2*i + 4) % 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Summer_School",
   "language": "python",
   "name": "summer_school"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
